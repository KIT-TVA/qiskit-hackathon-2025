{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting Started\n",
    "- `conda create -n [env_name]`\n",
    "- `conda activate [env_name]`\n",
    "- `pip install -r ./requirements.txt`\n",
    "- `conda update -all`\n",
    "- `conda install -c conda-forge xgboost`"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('data/dummy.csv')\n",
    "df_configurations_with_id_with_duplicates = dataset[['ID', 'configuration']].copy()\n",
    "df_features_with_id = dataset.drop(['configuration'], axis=1).copy()"
   ],
   "id": "22632d7657304d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: possibly drop the \"or\" merging of labels. My assumption is that this makes the vectors too dense.\n",
    "# TODO: Analyze the passes for mutual exlusivity or other dependencies to include this information in the loss function.\n",
    "df_configurations_with_id_with_duplicates['config_arr'] = (\n",
    "    df_configurations_with_id_with_duplicates['configuration']\n",
    "      .apply(ast.literal_eval)          # \"[1,0,1,...]\" → [1,0,1,...]\n",
    "      .apply(lambda lst: np.array(lst, dtype=int))\n",
    ")\n",
    "df_ored_configuration = (\n",
    "    df_configurations_with_id_with_duplicates\n",
    "      .groupby('ID')['config_arr']\n",
    "      .agg(lambda arrs: np.bitwise_or.reduce(arrs.tolist()))\n",
    "      .reset_index()\n",
    "      .rename(columns={'config_arr':'label_vec'})\n",
    ")\n",
    "\n",
    "df_ored_configuration = df_ored_configuration[['ID','label_vec']].copy()\n",
    "\n",
    "df_features_unique = df_features_with_id.drop_duplicates(subset='ID')"
   ],
   "id": "b3727c5d28458191",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "single_value_cols = df_features_unique.columns[df_features_unique.nunique(dropna=False) == 1]\n",
    "\n",
    "df_feat = df_features_with_id.drop_duplicates('ID').set_index('ID')\n",
    "df_feat = df_feat.drop(single_value_cols, axis=1)\n",
    "\n",
    "df_lbl = df_ored_configuration.set_index('ID')\n",
    "y = np.vstack(df_lbl['label_vec'].values)\n",
    "\n",
    "X = df_feat.values"
   ],
   "id": "a09698f25b3ad685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration\n",
    "DO_HPO          = True\n",
    "HPO_NUM_TRIALS  = 40\n",
    "N_OUTER_FOLDS   = 10\n",
    "N_INNER_FOLDS   = 5\n",
    "RANDOM_STATE    = 43\n",
    "\n",
    "BASELINE_PARAMS = {\n",
    "    \"n_estimators\": 100,\n",
    "}"
   ],
   "id": "8bb42b84b1da85c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.metrics import make_scorer, hamming_loss\n",
    "\n",
    "base_clf = XGBClassifier(\n",
    "    **BASELINE_PARAMS,\n",
    "    objective='binary:logistic',\n",
    "    random_state=RANDOM_STATE,\n",
    "    tree_method='hist',\n",
    "    multi_strategy='multi_output_tree', # maybe without. This allows the model to learn label dependencies by training a single tree for all labels.\n",
    ")\n",
    "multiLabelClassifier = MultiOutputClassifier(base_clf, n_jobs=-1)\n",
    "\n",
    "outer_cv = MultilabelStratifiedKFold(\n",
    "    n_splits=N_OUTER_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "inner_cv = MultilabelStratifiedKFold(\n",
    "    n_splits=N_INNER_FOLDS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"f1_micro\": \"f1_micro\",\n",
    "    \"f1_macro\": \"f1_macro\",\n",
    "    \"hamming\": make_scorer(hamming_loss, greater_is_better=False)\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    multiLabelClassifier, X, y,\n",
    "    cv=outer_cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# TODO: feature importance study\n",
    "print(\"Outer-fold scores:\")\n",
    "for name in scoring:\n",
    "    mean = cv_results[f\"test_{name}\"].mean()\n",
    "    std  = cv_results[f\"test_{name}\"].std()\n",
    "    print(f\"  {name:>10s}: {mean:7.3f} ± {std:.3f}\")"
   ],
   "id": "6149493a27a59578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "multiLabelClassifier.fit(X, y)",
   "id": "eda87656e264caf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: Add evaluation code against default optimization routine",
   "id": "adfaa18b517cb9a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
